# -*- coding: utf-8 -*-
"""Semantic Segmentation of Aerial Images.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QEhfv9zC9gom2N147zsB_2BC6CmzsznK

# Semantic Segmentation of Aerial Images
by Salaheldin Bilila

## Kaggle and dataset setup
"""

#%tensorflow_version 1.x
import tensorflow as tf
print(tf.__version__)

#install kaggle
!pip install -q kaggle
#!pip install 'h5py==2.10.0' -q --force-reinstall

#install the kaggle token
import os
import json

kaggle_token = 'kaggle.json'
with open(kaggle_token, "w") as f:
            json.dump({
                "username": "salaheldinbilila",
                "key": "fb4ac125d79bb7f46ee78c67c47566c4"
            }, f)

#Create the .kaggle directory with the .json file inside it
!rm -r ~/.kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets list

# Download the dataset
!kaggle datasets download -d bulentsiyah/semantic-drone-dataset

# Commented out IPython magic to ensure Python compatibility.
# # Unzip the dataset
# %%capture
# !unzip semantic-drone-dataset.zip

!mv dataset/semantic_drone_dataset/original_images/ .
!mv dataset/semantic_drone_dataset/label_images_semantic/ .
!rm -r dataset semantic-drone-dataset.zip
!mkdir train_images train_masks val_images val_masks test_images test_masks checkpoints

# The paths for the dataset
import os
IMAGE_PATH = "original_images/"
MASK_PATH = "label_images_semantic/"

# Get the dataset file names using pandas
import pandas as pd
import numpy as np
def create_df(path):
    name = []
    for dirname, _, filenames in os.walk(path):
        for filename in filenames:
            name.append(filename.split('.')[0])

    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))

df = create_df('original_images/')
print('Total Images: ', len(df))

# Split the files into train,val,test
import random
data = list(df['id'].values)
total_len = len(data)
random.seed(24)
train_data = random.sample(data, int(0.7 * total_len))
remaining_data = list(set(data) - set(train_data))
validation_data = random.sample(remaining_data, int(0.15 * total_len))
test_data = list(set(remaining_data) - set(validation_data))
print('Train Size.     : ', len(train_data))
print('Validation Size : ', len(validation_data))
print('Test Size.      : ', len(test_data))

# Get the files and split to train,val,test folders
def split_dataset_files(data,img_path,mask_path,split):
  for i in range(len(data)):
    os.system('mv '+img_path+data[i]+'.jpg '+split+'_images/')
    os.system('mv '+mask_path+data[i]+'.png '+split+'_masks/')

split_dataset_files(train_data,IMAGE_PATH,MASK_PATH,'train')
split_dataset_files(validation_data,IMAGE_PATH,MASK_PATH,'val')
split_dataset_files(test_data,IMAGE_PATH,MASK_PATH,'test')

!rm -r original_images/ label_images_semantic/

"""## Data preprocessing and Libraries"""

#%tensorflow_version 1.x

#!pip install -q keras-segmentation
!git clone https://github.com/divamgupta/image-segmentation-keras
!cp -r image-segmentation-keras/keras_segmentation/ keras_segmentation/

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
# %matplotlib inline
from keras_segmentation.models.unet import resnet50_unet
import cv2 as cv
from google.colab.patches import cv2_imshow

BASE_PATH = 'drive/MyDrive/Semantic_Drone/dataset/'
TRAIN_IMAGES = BASE_PATH + 'train_images/'
TRAIN_MASKS = BASE_PATH + 'train_masks/'
VAL_IMAGES = BASE_PATH + 'val_images/'
VAL_MASKS = BASE_PATH + 'val_masks/'
TEST_IMAGES = BASE_PATH + 'test_images/'
TEST_MASKS = BASE_PATH + 'test_masks/'
CHECKPOINT_PATH = BASE_PATH + 'checkpoints/checkpoint'
#CHECKPOINT_PATH = 'checkpoint'

color_map = pd.read_csv(BASE_PATH + 'class_dict_seg.csv').to_dict()
color_map['name']
classes = {v: k for k, v in color_map['name'].items()}
classes

# Prepare color_map
#color_map = pd.read_csv('/content/class_dict_seg.csv').to_dict('index')
color_map = pd.read_csv(BASE_PATH + 'class_dict_seg.csv').to_dict('index')
del color_map[23]
for key in color_map:
  color_map[key]['rgb']=[color_map[key][' r'],color_map[key][' g'],color_map[key][' b']]
  del color_map[key][' r']
  del color_map[key][' g']
  del color_map[key][' b']
color_map

# List of color tuples of the classes & class names
class_colors = [tuple(color_map[key]['rgb']) for key in color_map]
class_names = [color_map[key]['name'] for key in color_map]

# Get the colored mask from the segmented mask
def mask_to_color(mask,map_dict):
  rgb_mask = np.zeros(mask.shape + (3,),dtype=np.uint8)
  for key in np.unique(mask):
    rgb_mask[mask==key] = map_dict[key]['rgb']
  return rgb_mask

# Get the legend handles required for plotting
def create_legend_handles(mask,map_dict):
  handles = []
  for key in np.unique(mask):
    color_val = [x/255.0 for x in map_dict[key]['rgb']]
    name = map_dict[key]['name']
    h = mpatches.Patch(color=tuple(color_val), label=name)
    handles.append(h)
  return handles

model = resnet50_unet(n_classes=23 ,  input_height=416, input_width=608)
#model = resnet50_unet(n_classes=23 ,  input_height=704, input_width=1056)

!cp -r drive/MyDrive/Semantic_Drone/dataset/checkpoints/ .

"""## Training"""

model.train(
    train_images = TRAIN_IMAGES,
    train_annotations = TRAIN_MASKS,
    checkpoints_path = CHECKPOINT_PATH,
    verify_dataset=False,
    validate = True,
    val_images = VAL_IMAGES,
    val_annotations = VAL_MASKS,
    auto_resume_checkpoint=True,
    batch_size=2,
    #do_augment=True,
    steps_per_epoch=None,
    val_steps_per_epoch=None,
    gen_use_multiprocessing=True,
    epochs=15
)

!cp -r checkpoints/ drive/MyDrive/Semantic_Drone/dataset/checkpoints/

"""## Testing"""

from keras_segmentation.train import find_latest_checkpoint
latest_checkpoint = find_latest_checkpoint(CHECKPOINT_PATH)
print(latest_checkpoint)
model.load_weights(latest_checkpoint)

metrics = model.evaluate_segmentation(
    inp_images_dir=TEST_IMAGES,
    annotations_dir=TEST_MASKS,
    checkpoints_path=CHECKPOINT_PATH
)
print(metrics)

from keras_segmentation.predict import predict
out_label = model.predict_segmentation(
#_ = predict(
    inp=TRAIN_IMAGES+'000.jpg',
    #overlay_img = True,
    #colors = class_colors,
    checkpoints_path=CHECKPOINT_PATH
)

import glob
from tqdm import tqdm
from keras_segmentation.data_utils.data_loader import get_image_array
import random

output_width = model.output_width
output_height = model.output_height
input_width = model.input_width
input_height = model.input_height
n_classes = model.n_classes
inps = glob.glob(os.path.join(TEST_IMAGES, "*.jpg")) + glob.glob(
    os.path.join(TEST_IMAGES, "*.png")) + \
    glob.glob(os.path.join(TEST_IMAGES, "*.jpeg"))
inps = sorted(inps)
for inp in tqdm(random.sample(inps,3)):
  inp = cv.imread(inp, 1)
  x = get_image_array(inp, input_width, input_height,ordering=None)
  pr = model.predict(np.array([x]))[0]
  pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)
  pr = cv.resize(pr, (inp.shape[1], inp.shape[0]), interpolation=cv.INTER_NEAREST)
  h=create_legend_handles(pr,color_map)
  pr = mask_to_color(pr,color_map)
  inp = cv.cvtColor(inp,cv.COLOR_BGR2RGB)
  fig ,arr  = plt.subplots(1,3,figsize=(20,15))
  arr[0].imshow(inp)
  arr[0].set_title('Original Image')
  arr[1].imshow(inp)
  arr[1].imshow(pr,alpha=0.5)
  arr[1].set_title('Segmented Image')
  arr[2].imshow(pr)
  arr[2].set_title('Mask')
  arr[2].legend(handles=h,bbox_to_anchor=(1, 0.5), loc='center left')

x = cv.imread(inps[0], 1)
x = get_image_array(x, input_width, input_height,ordering=None)
x.dtype
#plt.imshow(x)

"""## Holyrood Dataset Training

"""

!cp -r /content/drive/MyDrive/Semantic_Drone/Holyrood_Dataset/ Holyrood_Dataset/

BASE_PATH = '/content/drive/MyDrive/Semantic_Drone/Holyrood_Dataset/'
TRAIN_IMAGES = BASE_PATH + 'images/'
TRAIN_MASKS = BASE_PATH + 'masks/'
TEST_IMAGES = BASE_PATH + 'test/'
CHECKPOINT_PATH = BASE_PATH + 'checkpoints/checkpoint'

model.train(
    train_images = TRAIN_IMAGES,
    train_annotations = TRAIN_MASKS,
    checkpoints_path = CHECKPOINT_PATH,
    batch_size=2,
    verify_dataset=True,
    auto_resume_checkpoint=True,
    steps_per_epoch=None,
    epochs=15
)

checkpoint = CHECKPOINT_PATH+'.14'
print(checkpoint)
model.load_weights(checkpoint)

inp = TRAIN_IMAGES + 'DJI_0188.jpg'
inp = cv.imread(inp, 1)
gt = TRAIN_MASKS + 'DJI_0188.png'
gt = cv.imread(gt,0)
gt = mask_to_color(gt,color_map)
x = get_image_array(inp, input_width, input_height,ordering=None)
pr = model.predict(np.array([x]))[0]
pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)
pr = cv.resize(pr, (inp.shape[1], inp.shape[0]), interpolation=cv.INTER_NEAREST)
h=create_legend_handles(pr,color_map)
pr = mask_to_color(pr,color_map)
inp = cv.cvtColor(inp,cv.COLOR_BGR2RGB)
fig ,arr  = plt.subplots(1,3,figsize=(20,15))
arr[0].imshow(inp)
arr[0].set_title('Original Image')
arr[2].imshow(gt)
arr[2].set_title('Ground Truth')
arr[1].imshow(pr)
arr[1].set_title('Mask')
arr[2].legend(handles=h,bbox_to_anchor=(1, 0.5), loc='center left')

import glob
from tqdm import tqdm
from keras_segmentation.data_utils.data_loader import get_image_array

output_width = model.output_width
output_height = model.output_height
input_width = model.input_width
input_height = model.input_height
n_classes = model.n_classes
inps = glob.glob(os.path.join(TEST_IMAGES, "*.jpg")) + \
    glob.glob(os.path.join(TEST_IMAGES, "*.JPG"))
inps = sorted(inps)
for inp in tqdm(inps):
  inp = cv.imread(inp, 1)
  x = get_image_array(inp, input_width, input_height,ordering=None)
  pr = model.predict(np.array([x]))[0]
  pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)
  pr = cv.resize(pr, (inp.shape[1], inp.shape[0]), interpolation=cv.INTER_NEAREST)
  h=create_legend_handles(pr,color_map)
  pr = mask_to_color(pr,color_map)
  inp = cv.cvtColor(inp,cv.COLOR_BGR2RGB)
  fig ,arr  = plt.subplots(1,3,figsize=(20,15))
  arr[0].imshow(inp)
  arr[0].set_title('Original Image')
  arr[1].imshow(inp)
  arr[1].imshow(pr,alpha=0.5)
  arr[1].set_title('Segmented Image')
  arr[2].imshow(pr)
  arr[2].set_title('Mask')
  arr[2].legend(handles=h,bbox_to_anchor=(1, 0.5), loc='center left')

"""## Bell 412 dataset"""

BASE_PATH = '/content/drive/MyDrive/dataset_toSalah/'
TEST_IMAGES = BASE_PATH + 'pics/'

# New weights
import glob
from tqdm import tqdm
from keras_segmentation.data_utils.data_loader import get_image_array

output_width = model.output_width
output_height = model.output_height
input_width = model.input_width
input_height = model.input_height
n_classes = model.n_classes
inps = glob.glob(os.path.join(TEST_IMAGES, "*.jpg")) + \
    glob.glob(os.path.join(TEST_IMAGES, "*.JPG"))
inps = sorted(inps)
for inp in tqdm(inps):
  inp = cv.imread(inp, 1)
  x = get_image_array(inp, input_width, input_height,ordering=None)
  pr = model.predict(np.array([x]))[0]
  pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)
  pr = cv.resize(pr, (inp.shape[1], inp.shape[0]), interpolation=cv.INTER_NEAREST)
  h=create_legend_handles(pr,color_map)
  pr = mask_to_color(pr,color_map)
  inp = cv.cvtColor(inp,cv.COLOR_BGR2RGB)
  fig ,arr  = plt.subplots(1,3,figsize=(20,15))
  arr[0].imshow(inp)
  arr[0].set_title('Original Image')
  arr[1].imshow(inp)
  arr[1].imshow(pr,alpha=0.5)
  arr[1].set_title('Segmented Image')
  arr[2].imshow(pr)
  arr[2].set_title('Mask')
  arr[2].legend(handles=h,bbox_to_anchor=(1, 0.5), loc='center left')

# Old weights
import glob
from tqdm import tqdm
from keras_segmentation.data_utils.data_loader import get_image_array

output_width = model.output_width
output_height = model.output_height
input_width = model.input_width
input_height = model.input_height
n_classes = model.n_classes
inps = glob.glob(os.path.join(TEST_IMAGES, "*.jpg")) + \
    glob.glob(os.path.join(TEST_IMAGES, "*.JPG"))
inps = sorted(inps)
for inp in tqdm(inps):
  inp = cv.imread(inp, 1)
  x = get_image_array(inp, input_width, input_height,ordering=None)
  pr = model.predict(np.array([x]))[0]
  pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)
  pr = cv.resize(pr, (inp.shape[1], inp.shape[0]), interpolation=cv.INTER_NEAREST)
  h=create_legend_handles(pr,color_map)
  pr = mask_to_color(pr,color_map)
  inp = cv.cvtColor(inp,cv.COLOR_BGR2RGB)
  fig ,arr  = plt.subplots(1,3,figsize=(20,15))
  arr[0].imshow(inp)
  arr[0].set_title('Original Image')
  arr[1].imshow(inp)
  arr[1].imshow(pr,alpha=0.5)
  arr[1].set_title('Segmented Image')
  arr[2].imshow(pr)
  arr[2].set_title('Mask')
  arr[2].legend(handles=h,bbox_to_anchor=(1, 0.5), loc='center left')